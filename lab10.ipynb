{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "softmax(1단) vs Neural Net('여러 단'): 90%->94.5%\n",
    "'Xavier' initialization: 97.8%\n",
    "여기서 더 노드를 추가하면 오버피팅의 문제->dropout사용\n",
    "Deep Neural Nets with 'Dropout': 98%'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch:  0001 cost =  5.287762468\n",
      "Epoch:  0002 cost =  1.604718128\n",
      "Epoch:  0003 cost =  1.102973436\n",
      "Epoch:  0004 cost =  0.898260206\n",
      "Epoch:  0005 cost =  0.776920890\n",
      "Epoch:  0006 cost =  0.695094529\n",
      "Epoch:  0007 cost =  0.634155329\n",
      "Epoch:  0008 cost =  0.587389937\n",
      "Epoch:  0009 cost =  0.549488409\n",
      "Epoch:  0010 cost =  0.519575230\n",
      "Epoch:  0011 cost =  0.494719444\n",
      "Epoch:  0012 cost =  0.473277276\n",
      "Epoch:  0013 cost =  0.454528257\n",
      "Epoch:  0014 cost =  0.438727241\n",
      "Epoch:  0015 cost =  0.424769293\n",
      "Epoch:  0016 cost =  0.412826915\n",
      "Epoch:  0017 cost =  0.401962468\n",
      "Epoch:  0018 cost =  0.391703650\n",
      "Epoch:  0019 cost =  0.383217430\n",
      "Epoch:  0020 cost =  0.375205271\n",
      "Epoch:  0021 cost =  0.367515170\n",
      "Epoch:  0022 cost =  0.361001784\n",
      "Epoch:  0023 cost =  0.354154138\n",
      "Epoch:  0024 cost =  0.348552979\n",
      "Epoch:  0025 cost =  0.343018991\n",
      "Epoch:  0026 cost =  0.338088314\n",
      "Epoch:  0027 cost =  0.333169601\n",
      "Epoch:  0028 cost =  0.329110760\n",
      "Epoch:  0029 cost =  0.324837861\n",
      "Epoch:  0030 cost =  0.320764724\n",
      "Epoch:  0031 cost =  0.317641378\n",
      "Epoch:  0032 cost =  0.313302272\n",
      "Epoch:  0033 cost =  0.310633389\n",
      "Epoch:  0034 cost =  0.307953440\n",
      "Epoch:  0035 cost =  0.304316688\n",
      "Epoch:  0036 cost =  0.301937659\n",
      "Epoch:  0037 cost =  0.299405329\n",
      "Epoch:  0038 cost =  0.296655900\n",
      "Epoch:  0039 cost =  0.293948377\n",
      "Epoch:  0040 cost =  0.291812490\n",
      "Epoch:  0041 cost =  0.289397152\n",
      "Epoch:  0042 cost =  0.287165812\n",
      "Epoch:  0043 cost =  0.285281650\n",
      "Epoch:  0044 cost =  0.283470551\n",
      "Epoch:  0045 cost =  0.281986760\n",
      "Epoch:  0046 cost =  0.279837867\n",
      "Epoch:  0047 cost =  0.278380979\n",
      "Epoch:  0048 cost =  0.276859716\n",
      "Epoch:  0049 cost =  0.275437577\n",
      "Epoch:  0050 cost =  0.273374230\n",
      "Learning Finished!\n",
      "Accuracy:  0.9192\n",
      "Label:  [8]\n",
      "prediction:  [8]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\\nsoftmax(1단) vs Neural Net('여러 단'): 90%->94.5%\\n'Xavier' initialization: 97.8%\\n여기서 더 노드를 추가하면 오버피팅의 문제->dropout사용\\nDeep Neural Nets with 'Dropout': 98%\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#softmax classifier for MNIST\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([784,10]))#784개의 벡터가 입력, out: 10(0-9까지)\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_epoch = 50\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = hypothesis, labels = Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(training_epoch):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "        for iteration in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict = {X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "        print('Epoch: ', '%04d' %(epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))\n",
    "    print('Learning Finished!')\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, axis = 1), tf.argmax(Y, axis = 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print('Accuracy: ', sess.run(accuracy, feed_dict = {X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    \n",
    "    print('Label: ', sess.run(tf.argmax(mnist.test.labels[r:r+1], axis = 1)))\n",
    "    print('prediction: ',\n",
    "         sess.run(\n",
    "         tf.argmax(hypothesis, axis = 1), feed_dict = {X: mnist.test.images[r: r+1]}),)\n",
    "    \n",
    "    plt.imshow(\n",
    "        mnist.test.images[r: r+1].reshape(28,28),\n",
    "        cmap = 'Greys',\n",
    "        interpolation = 'nearest',\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 cost =  157.576586422\n",
      "Epoch:  0002 cost =  42.299128336\n",
      "Epoch:  0003 cost =  26.620276166\n",
      "Epoch:  0004 cost =  18.296517631\n",
      "Epoch:  0005 cost =  13.531353110\n",
      "Epoch:  0006 cost =  10.137256851\n",
      "Epoch:  0007 cost =  7.368654977\n",
      "Epoch:  0008 cost =  5.509895640\n",
      "Epoch:  0009 cost =  4.094763815\n",
      "Epoch:  0010 cost =  3.071100343\n",
      "Epoch:  0011 cost =  2.281294159\n",
      "Epoch:  0012 cost =  1.746653765\n",
      "Epoch:  0013 cost =  1.315559733\n",
      "Epoch:  0014 cost =  1.021366695\n",
      "Epoch:  0015 cost =  0.818439385\n",
      "Epoch:  0016 cost =  0.705058161\n",
      "Epoch:  0017 cost =  0.620700402\n",
      "Epoch:  0018 cost =  0.581238982\n",
      "Epoch:  0019 cost =  0.487193047\n",
      "Epoch:  0020 cost =  0.452537070\n",
      "Epoch:  0021 cost =  0.383514902\n",
      "Epoch:  0022 cost =  0.420286327\n",
      "Epoch:  0023 cost =  0.386705441\n",
      "Epoch:  0024 cost =  0.316619114\n",
      "Epoch:  0025 cost =  0.292227929\n",
      "Epoch:  0026 cost =  0.382204969\n",
      "Epoch:  0027 cost =  0.285564513\n",
      "Epoch:  0028 cost =  0.323911105\n",
      "Epoch:  0029 cost =  0.238742795\n",
      "Epoch:  0030 cost =  0.293635220\n",
      "Epoch:  0031 cost =  0.196242276\n",
      "Epoch:  0032 cost =  0.258702923\n",
      "Epoch:  0033 cost =  0.327793550\n",
      "Epoch:  0034 cost =  0.222790180\n",
      "Epoch:  0035 cost =  0.211344393\n",
      "Epoch:  0036 cost =  0.233570049\n",
      "Epoch:  0037 cost =  0.280762034\n",
      "Epoch:  0038 cost =  0.242890175\n",
      "Epoch:  0039 cost =  0.148467984\n",
      "Epoch:  0040 cost =  0.179538107\n",
      "Epoch:  0041 cost =  0.224601426\n",
      "Epoch:  0042 cost =  0.251324021\n",
      "Epoch:  0043 cost =  0.244431300\n",
      "Epoch:  0044 cost =  0.100587955\n",
      "Epoch:  0045 cost =  0.143273933\n",
      "Epoch:  0046 cost =  0.206028611\n",
      "Epoch:  0047 cost =  0.146988282\n",
      "Epoch:  0048 cost =  0.194284749\n",
      "Epoch:  0049 cost =  0.109309737\n",
      "Epoch:  0050 cost =  0.192282223\n",
      "Learning Finished!\n",
      "Accuracy:  0.9648\n",
      "Label:  [7]\n",
      "Prediction:  [7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#NN for mnist\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784,256]))\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256,256]))\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256,10]))\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L2, W3) + b3\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = hypothesis, labels = Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epoch):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        \n",
    "        for iteration in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict = {X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        print('Epoch: ', '%04d'%(epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))\n",
    "    print('Learning Finished!')\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, axis = 1), tf.argmax(Y, axis = 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print('Accuracy: ', sess.run(accuracy, feed_dict = {X: mnist.test.images, Y: mnist.test.labels}))\n",
    "    \n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    \n",
    "    print('Label: ', sess.run(tf.argmax(mnist.test.labels[r:r+1], axis = 1)))\n",
    "    print('Prediction: ',\n",
    "         sess.run(tf.argmax(hypothesis, axis = 1), feed_dict=  {X: mnist.test.images[r:r+1]}),)\n",
    "    \n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28,28),\n",
    "              cmap = 'Greys',\n",
    "              interpolation = 'nearest',)\n",
    "    plt.show()\n",
    "#epoch, batch_size iteration 다 그대로 사용\n",
    "#weight의 크기를 구하는게 중요, W1에서는 입력이 784, out은 256(그냥 정하면됨)\n",
    "#맨 마지막은 10개로 확정\n",
    "#overfitting->학습데이터를 너무 잘 기억해버리면 새로운 데이터가 들어왔을 때 추정을 못함.\n",
    "#dropout: 네트워크가 오버피팅 되지 않도록 일부를 끊고 학습을 시킴\n",
    "#텐서플로에서는 드롭아웃 레이어를 하나 더 넣어줌.\n",
    "#dropout-> keep_prob(전체중 몇%의 네트웍을 keep해줄것인가): train할 때는 0.5~0.7(좀 쉬고 몇 %만 트레이닝 하자)\n",
    "#실전에서는 '반드시' dropout을 1\n",
    "#feed_dict에서 0.7만큼 드롭아웃\n",
    "#optimizer-> 다양한 옵티마이저가 있음.\n",
    "#AdamOptimizer-> 다른 형태의 옵티마이저\n",
    "#batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.298920871\n",
      "Epoch: 0002 cost = 0.107996223\n",
      "Epoch: 0003 cost = 0.069463847\n",
      "Epoch: 0004 cost = 0.050363309\n",
      "Epoch: 0005 cost = 0.036342969\n",
      "Epoch: 0006 cost = 0.029120363\n",
      "Epoch: 0007 cost = 0.022991249\n",
      "Epoch: 0008 cost = 0.016806440\n",
      "Epoch: 0009 cost = 0.016912465\n",
      "Epoch: 0010 cost = 0.012465208\n",
      "Epoch: 0011 cost = 0.011911555\n",
      "Epoch: 0012 cost = 0.012576086\n",
      "Epoch: 0013 cost = 0.009762107\n",
      "Epoch: 0014 cost = 0.011095417\n",
      "Epoch: 0015 cost = 0.008301703\n",
      "Epoch: 0016 cost = 0.009517114\n",
      "Epoch: 0017 cost = 0.008371277\n",
      "Epoch: 0018 cost = 0.004781670\n",
      "Epoch: 0019 cost = 0.009468397\n",
      "Epoch: 0020 cost = 0.009858462\n",
      "Epoch: 0021 cost = 0.007321376\n",
      "Epoch: 0022 cost = 0.005940149\n",
      "Epoch: 0023 cost = 0.004470377\n",
      "Epoch: 0024 cost = 0.004343228\n",
      "Epoch: 0025 cost = 0.012208348\n",
      "Epoch: 0026 cost = 0.004101054\n",
      "Epoch: 0027 cost = 0.003117073\n",
      "Epoch: 0028 cost = 0.003431736\n",
      "Epoch: 0029 cost = 0.007674033\n",
      "Epoch: 0030 cost = 0.005888326\n",
      "Epoch: 0031 cost = 0.006139250\n",
      "Epoch: 0032 cost = 0.004600020\n",
      "Epoch: 0033 cost = 0.005377664\n",
      "Epoch: 0034 cost = 0.003218581\n",
      "Epoch: 0035 cost = 0.003635088\n",
      "Epoch: 0036 cost = 0.003907748\n",
      "Epoch: 0037 cost = 0.006379429\n",
      "Epoch: 0038 cost = 0.007717225\n",
      "Epoch: 0039 cost = 0.000857708\n",
      "Epoch: 0040 cost = 0.000109507\n",
      "Epoch: 0041 cost = 0.002002604\n",
      "Epoch: 0042 cost = 0.012933946\n",
      "Epoch: 0043 cost = 0.005070867\n",
      "Epoch: 0044 cost = 0.001307880\n",
      "Epoch: 0045 cost = 0.004704544\n",
      "Epoch: 0046 cost = 0.005693614\n",
      "Epoch: 0047 cost = 0.004462587\n",
      "Epoch: 0048 cost = 0.002988029\n",
      "Epoch: 0049 cost = 0.002901937\n",
      "Epoch: 0050 cost = 0.004381254\n",
      "Learning Finished!\n",
      "Accuracy:  0.9786\n",
      "Label:  [9]\n",
      "Prediction:  [9]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Xavier for mnist\n",
    "tf.reset_default_graph()#get_variable은 위의 걸 가져오는거라서 먼저 초기화시켜야함\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "W1 = tf.get_variable(\"W1\", shape = [784, 256], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.get_variable('W2', shape = [256, 256], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "W3 = tf.get_variable('W3', shape = [256, 10], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L2, W3) + b3\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = hypothesis, labels = Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_epoch = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epoch):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        \n",
    "        for iteration in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict = {X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "        \n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "    print('Learning Finished!')\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, axis = 1), tf.argmax(Y, axis = 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print('Accuracy: ', sess.run(accuracy, feed_dict = {X: mnist.test.images, Y: mnist.test.labels}))\n",
    "    \n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    \n",
    "    print('Label: ', sess.run(tf.argmax(mnist.test.labels[r:r+1], axis = 1)))\n",
    "    print('Prediction: ', sess.run(tf.argmax(hypothesis, axis = 1), feed_dict= {X: mnist.test.images[r:r+1]}),)\n",
    "    \n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28,28),\n",
    "              cmap = 'Greys',\n",
    "              interpolation = 'nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0001 cost =  0.302214093\n",
      "Epoch:  0002 cost =  0.104779627\n",
      "Epoch:  0003 cost =  0.069754901\n",
      "Epoch:  0004 cost =  0.054365800\n",
      "Epoch:  0005 cost =  0.040154218\n",
      "Epoch:  0006 cost =  0.032545072\n",
      "Epoch:  0007 cost =  0.031277332\n",
      "Epoch:  0008 cost =  0.021752477\n",
      "Epoch:  0009 cost =  0.023494756\n",
      "Epoch:  0010 cost =  0.020809496\n",
      "Epoch:  0011 cost =  0.018997755\n",
      "Epoch:  0012 cost =  0.017064759\n",
      "Epoch:  0013 cost =  0.017000294\n",
      "Epoch:  0014 cost =  0.013629394\n",
      "Epoch:  0015 cost =  0.014335067\n",
      "Epoch:  0016 cost =  0.012089055\n",
      "Epoch:  0017 cost =  0.012387544\n",
      "Epoch:  0018 cost =  0.012839215\n",
      "Epoch:  0019 cost =  0.010582299\n",
      "Epoch:  0020 cost =  0.014293560\n",
      "Epoch:  0021 cost =  0.012029016\n",
      "Epoch:  0022 cost =  0.007913630\n",
      "Epoch:  0023 cost =  0.009635913\n",
      "Epoch:  0024 cost =  0.012549133\n",
      "Epoch:  0025 cost =  0.007447746\n",
      "Epoch:  0026 cost =  0.010325008\n",
      "Epoch:  0027 cost =  0.005317006\n",
      "Epoch:  0028 cost =  0.010188674\n",
      "Epoch:  0029 cost =  0.010685735\n",
      "Epoch:  0030 cost =  0.007382327\n",
      "Epoch:  0031 cost =  0.006379167\n",
      "Epoch:  0032 cost =  0.007321216\n",
      "Epoch:  0033 cost =  0.007387567\n",
      "Epoch:  0034 cost =  0.010697967\n",
      "Epoch:  0035 cost =  0.008149541\n",
      "Epoch:  0036 cost =  0.004206817\n",
      "Epoch:  0037 cost =  0.008930235\n",
      "Epoch:  0038 cost =  0.009915476\n",
      "Epoch:  0039 cost =  0.007679882\n",
      "Epoch:  0040 cost =  0.005339815\n",
      "Epoch:  0041 cost =  0.004007933\n",
      "Epoch:  0042 cost =  0.009715365\n",
      "Epoch:  0043 cost =  0.006289531\n",
      "Epoch:  0044 cost =  0.006970020\n",
      "Epoch:  0045 cost =  0.006754410\n",
      "Epoch:  0046 cost =  0.004628819\n",
      "Epoch:  0047 cost =  0.009362567\n",
      "Epoch:  0048 cost =  0.006260218\n",
      "Epoch:  0049 cost =  0.004362654\n",
      "Epoch:  0050 cost =  0.009511262\n",
      "Learning Finished!\n",
      "Accuracy:  0.9771\n",
      "Label:  [8]\n",
      "Prediction:  [8]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "W1 = tf.get_variable('W1', shape = [784, 512], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([512]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.get_variable('W2', shape = [512, 512], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([512]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "W3 = tf.get_variable('W3', shape = [512, 512], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([512]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "\n",
    "W4 = tf.get_variable('W4', shape = [512, 512], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([512]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "\n",
    "W5 = tf.get_variable('W5', shape = [512, 10], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L4, W5) + b5\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = hypothesis, labels = Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epoch):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        \n",
    "        for iteration in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict = {X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        print('Epoch: ', '%04d'%(epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))\n",
    "    print('Learning Finished!')\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, axis = 1), tf.argmax(Y, axis = 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print('Accuracy: ', sess.run(accuracy, feed_dict = {X: mnist.test.images, Y: mnist.test.labels}))\n",
    "    \n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    \n",
    "    print('Label: ', sess.run(tf.argmax(mnist.test.labels[r:r+1], axis = 1)))\n",
    "    print('Prediction: ', sess.run(tf.argmax(hypothesis, axis = 1), feed_dict = {X: mnist.test.images[r:r+1]}),)\n",
    "    \n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28,28),\n",
    "              cmap = 'Greys',\n",
    "              interpolation = 'nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost =  0.400901487\n",
      "Epoch: 0002 cost =  0.160466005\n",
      "Epoch: 0003 cost =  0.114320425\n",
      "Epoch: 0004 cost =  0.099506435\n",
      "Epoch: 0005 cost =  0.084935138\n",
      "Epoch: 0006 cost =  0.077893027\n",
      "Epoch: 0007 cost =  0.068013393\n",
      "Epoch: 0008 cost =  0.064163955\n",
      "Epoch: 0009 cost =  0.057832674\n",
      "Epoch: 0010 cost =  0.053572740\n",
      "Epoch: 0011 cost =  0.049927062\n",
      "Epoch: 0012 cost =  0.050251175\n",
      "Epoch: 0013 cost =  0.047954192\n",
      "Epoch: 0014 cost =  0.043100720\n",
      "Epoch: 0015 cost =  0.039803729\n",
      "Epoch: 0016 cost =  0.038277272\n",
      "Epoch: 0017 cost =  0.040676913\n",
      "Epoch: 0018 cost =  0.040624977\n",
      "Epoch: 0019 cost =  0.036287868\n",
      "Epoch: 0020 cost =  0.035938086\n",
      "Epoch: 0021 cost =  0.033548188\n",
      "Epoch: 0022 cost =  0.033716273\n",
      "Epoch: 0023 cost =  0.034114145\n",
      "Epoch: 0024 cost =  0.033355159\n",
      "Epoch: 0025 cost =  0.029929838\n",
      "Epoch: 0026 cost =  0.027879659\n",
      "Epoch: 0027 cost =  0.034645901\n",
      "Epoch: 0028 cost =  0.031736999\n",
      "Epoch: 0029 cost =  0.027553525\n",
      "Epoch: 0030 cost =  0.030545123\n",
      "Epoch: 0031 cost =  0.029513307\n",
      "Epoch: 0032 cost =  0.029942391\n",
      "Epoch: 0033 cost =  0.027803283\n",
      "Epoch: 0034 cost =  0.029089288\n",
      "Epoch: 0035 cost =  0.027974601\n",
      "Epoch: 0036 cost =  0.027392576\n",
      "Epoch: 0037 cost =  0.025966026\n",
      "Epoch: 0038 cost =  0.026691088\n",
      "Epoch: 0039 cost =  0.024143839\n",
      "Epoch: 0040 cost =  0.025360088\n",
      "Epoch: 0041 cost =  0.025598922\n",
      "Epoch: 0042 cost =  0.025978871\n",
      "Epoch: 0043 cost =  0.023723657\n",
      "Epoch: 0044 cost =  0.024862293\n",
      "Epoch: 0045 cost =  0.020884308\n",
      "Epoch: 0046 cost =  0.026795255\n",
      "Epoch: 0047 cost =  0.027380224\n",
      "Epoch: 0048 cost =  0.022202425\n",
      "Epoch: 0049 cost =  0.020419558\n",
      "Epoch: 0050 cost =  0.027188862\n",
      "Learning Finished!\n",
      "Accuracy:  0.9836\n",
      "Label:  [1]\n",
      "Prediction: [1]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAMc0lEQVR4nO3db4hc9b3H8c/H2PrAFIlmDcHKTW8V7FJoEsZQ9VIs5Qb1gbEPemmEkoqQShRaqejSEhuE4HLpH31wCaQaEi+9lkIbDCLXhliUgpRsJNXY0GrDtk2NyYQ80DwxNf3eB3u8rMnOmc2cc+ZM9vt+wXBmzm/2d74M+9nfzPmd2Z8jQgAWvkvaLgDAcBB2IAnCDiRB2IEkCDuQxKXDPNjSpUtjxYoVwzwkkMr09LROnjzpudoqhd32bZKelLRI0lMRMVn2/BUrVmhqaqrKIQGU6HQ6PdsGfhtve5Gk/5J0u6RxSettjw/aH4BmVfnMvkbS2xFxJCLOSPq5pHX1lAWgblXCfo2kv816fLTY9zG2N9qesj3V7XYrHA5AFVXCPtdJgPOuvY2I7RHRiYjO2NhYhcMBqKJK2I9KunbW409LeqdaOQCaUiXs+yVdb/sztj8p6euS9tRTFoC6DTz1FhEf2n5A0ouamXrbERFv1lYZgFpVmmePiBckvVBTLQAaxOWyQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiQx1CWbgdkizltA6GM2b95c2r5169bS9kceeaRn2+Rk6YLDCxIjO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTw7WrN///7S9scff7y0/ZJLyscq2xdc00JWKey2pyW9L+mspA8jolNHUQDqV8fI/uWIOFlDPwAaxGd2IImqYQ9Jv7Z9wPbGuZ5ge6PtKdtT3W634uEADKpq2G+JiNWSbpd0v+0vnfuEiNgeEZ2I6IyNjVU8HIBBVQp7RLxTbE9I2i1pTR1FAajfwGG3fbntT310X9JaSYfqKgxAvaqcjV8maXcxl3mppP+JiP+tpSqk8Pzzzzfa/5133tlo/xebgcMeEUckfaHGWgA0iKk3IAnCDiRB2IEkCDuQBGEHkuArrmjUkSNHerY99dRTlfpeu3Ztafvq1asr9b/QMLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBLMs6NRmzZt6tl2/PjxSn0/+uijpe2XXXZZpf4XGkZ2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCeXZUcubMmdL206dPD9z3FVdcUdo+Pj4+cN8ZMbIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBLMs6NUv3n0iYmJ0vZXX3114GM/+OCDpe395uHxcX1Hdts7bJ+wfWjWvitt77X9VrFd0myZAKqaz9v4nZJuO2ffhKR9EXG9pH3FYwAjrG/YI+IVSafO2b1O0q7i/i5Jd9VcF4CaDXqCbllEHJOkYnt1ryfa3mh7yvZUt9sd8HAAqmr8bHxEbI+ITkR0xsbGmj4cgB4GDftx28slqdieqK8kAE0YNOx7JG0o7m+Q9Fw95QBoSt95dtvPSrpV0lLbRyX9QNKkpF/YvlfSXyV9rcki0Z7p6enS9ieffHLgvvutr/7www8P3DfO1zfsEbG+R9NXaq4FQIO4XBZIgrADSRB2IAnCDiRB2IEk+IorSr377ruN9X3zzTeXtrPkcr0Y2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCebZk/vggw9K27ds2VKp/7L/TrRp06ZKfePCMLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBLMsye3devW0vaXX365Uv+7d+/u2XbVVVdV6hsXhpEdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Jgnn2B63a7pe3btm2r1P+yZctK26+77rpK/aM+fUd22ztsn7B9aNa+Lbb/bvtgcbuj2TIBVDWft/E7Jd02x/6fRMTK4vZCvWUBqFvfsEfEK5JODaEWAA2qcoLuAduvF2/zl/R6ku2NtqdsT/X7/AigOYOGfZukz0paKemYpB/1emJEbI+ITkR0yv75IIBmDRT2iDgeEWcj4p+SfippTb1lAajbQGG3vXzWw69KOtTruQBGQ995dtvPSrpV0lLbRyX9QNKttldKCknTkr7VYI3oo+x/v09MTJT+7KlT5ede+82jv/TSS6XtfHQbHX3DHhHr59j9dAO1AGgQl8sCSRB2IAnCDiRB2IEkCDuQBF9xXQAmJyd7tu3cubNS3zfddFNp+w033FCpfwwPIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME8+0XgwIEDpe1PPPFEY8d+6KGHGusbw8XIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM8+Asr+FbQkbd68ubT9vffeG/jYe/fuLW2/8cYbB+4bo4WRHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJ59CM6cOVPa/swzz5S2v/jiiwMf++677y5tHx8fL22/9FJ+RRaKviO77Wtt/8b2Ydtv2v52sf9K23ttv1VslzRfLoBBzedt/IeSvhsRn5P0RUn32x6XNCFpX0RcL2lf8RjAiOob9og4FhGvFfffl3RY0jWS1knaVTxtl6S7mioSQHUXdILO9gpJqyT9TtKyiDgmzfxBkHR1j5/ZaHvK9lS3261WLYCBzTvsthdL+qWk70TEvL95ERHbI6ITEZ2xsbFBagRQg3mF3fYnNBP0n0XEr4rdx20vL9qXSzrRTIkA6tB3XsW2JT0t6XBE/HhW0x5JGyRNFtvnGqlwAeg39XbfffdV6n/VqlU92/ot2bxo0aJKx8bFYz6TqLdI+oakN2wfLPZ9TzMh/4XteyX9VdLXmikRQB36hj0ifivJPZq/Um85AJrC5bJAEoQdSIKwA0kQdiAJwg4kwfcXF4Cyr6Eyj46PMLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBLMs18E7rnnntL2xx57bEiV4GLGyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDPPgSLFy8ubT979uyQKkFmjOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kETfsNu+1vZvbB+2/abtbxf7t9j+u+2Dxe2O5ssFMKj5XFTzoaTvRsRrtj8l6YDtvUXbTyLih82VB6Au81mf/ZikY8X9920flnRN04UBqNcFfWa3vULSKkm/K3Y9YPt12ztsL+nxMxttT9me6na7lYoFMLh5h932Ykm/lPSdiHhP0jZJn5W0UjMj/4/m+rmI2B4RnYjojI2N1VAygEHMK+y2P6GZoP8sIn4lSRFxPCLORsQ/Jf1U0prmygRQ1XzOxlvS05IOR8SPZ+1fPutpX5V0qP7yANRlPmfjb5H0DUlv2D5Y7PuepPW2V0oKSdOSvtVIhQBqMZ+z8b+V5DmaXqi/HABN4Qo6IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEo6I4R3M7kr6y6xdSyWdHFoBF2ZUaxvVuiRqG1Sdtf1LRMz5/9+GGvbzDm5PRUSntQJKjGpto1qXRG2DGlZtvI0HkiDsQBJth317y8cvM6q1jWpdErUNaii1tfqZHcDwtD2yAxgSwg4k0UrYbd9m+4+237Y90UYNvdietv1GsQz1VMu17LB9wvahWfuutL3X9lvFds419lqqbSSW8S5ZZrzV167t5c+H/pnd9iJJf5L075KOStovaX1E/GGohfRge1pSJyJavwDD9pcknZb0TER8vtj3n5JORcRk8YdySUQ8MiK1bZF0uu1lvIvVipbPXmZc0l2SvqkWX7uSuv5DQ3jd2hjZ10h6OyKORMQZST+XtK6FOkZeRLwi6dQ5u9dJ2lXc36WZX5ah61HbSIiIYxHxWnH/fUkfLTPe6mtXUtdQtBH2ayT9bdbjoxqt9d5D0q9tH7C9se1i5rAsIo5JM788kq5uuZ5z9V3Ge5jOWWZ8ZF67QZY/r6qNsM+1lNQozf/dEhGrJd0u6f7i7SrmZ17LeA/LHMuMj4RBlz+vqo2wH5V07azHn5b0Tgt1zCki3im2JyTt1ugtRX38oxV0i+2Jluv5f6O0jPdcy4xrBF67Npc/byPs+yVdb/sztj8p6euS9rRQx3lsX16cOJHtyyWt1egtRb1H0obi/gZJz7VYy8eMyjLevZYZV8uvXevLn0fE0G+S7tDMGfk/S/p+GzX0qOtfJf2+uL3Zdm2SntXM27p/aOYd0b2SrpK0T9JbxfbKEartvyW9Iel1zQRreUu1/ZtmPhq+Lulgcbuj7deupK6hvG5cLgskwRV0QBKEHUiCsANJEHYgCcIOJEHYgSQIO5DE/wGnm7v5cN682AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "W1 = tf.get_variable('W1', shape = [784, 512], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([512]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
    "L1 = tf.nn.dropout(L1, keep_prob = keep_prob)\n",
    "\n",
    "W2 = tf.get_variable('W2', shape = [512, 512], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([512]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "L2 = tf.nn.dropout(L2, keep_prob = keep_prob)\n",
    "\n",
    "W3 = tf.get_variable('W3', shape = [512, 512], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([512]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob = keep_prob)\n",
    "\n",
    "W4 = tf.get_variable('W4', shape = [512, 512], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([512]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob = keep_prob)\n",
    "\n",
    "W5 = tf.get_variable('W5', shape = [512, 10], initializer = tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L4, W5) + b5\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = hypothesis, labels = Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epoch):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        \n",
    "        for iteration in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7})\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        print('Epoch:', '%04d'%(epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))\n",
    "    print('Learning Finished!')\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, axis = 1), tf.argmax(Y, axis = 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print('Accuracy: ', sess.run(accuracy, feed_dict = {X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
    "    \n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print('Label: ', sess.run(tf.argmax(mnist.test.labels[r:r+1], axis = 1)))\n",
    "    print('Prediction:', sess.run(tf.argmax(hypothesis, axis = 1), feed_dict = {X: mnist.test.images[r:r+1], keep_prob: 1}))\n",
    "    \n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28,28),\n",
    "              cmap = 'Greys',\n",
    "              interpolation = 'nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-cf8a2e0dc367>:10: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001A721C59BC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001A721C59BC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001A721C59BC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001A721C59BC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001A7218A5848>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001A7218A5848>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001A7218A5848>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001A7218A5848>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001A721C39508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001A721C39508>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001A721C39508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001A721C39508>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001A7218A5848>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001A7218A5848>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001A7218A5848>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001A7218A5848>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001A721D315C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001A721D315C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001A721D315C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001A721D315C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001A721C58A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001A721C58A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001A721C58A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001A721C58A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001A721D315C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001A721D315C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001A721D315C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001A721D315C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001A721D46208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001A721D46208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001A721D46208>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000001A721D46208>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001A721D39148>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001A721D39148>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001A721D39148>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001A721D39148>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-1-cf8a2e0dc367>:49: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "[Epoch:    1] cost = 0.385021312\n",
      "[Epoch:    2] cost = 0.330945265\n",
      "[Epoch:    3] cost = 0.32151347\n",
      "[Epoch:    4] cost = 0.314746348\n",
      "[Epoch:    5] cost = 0.311675545\n",
      "[Epoch:    6] cost = 0.311172576\n",
      "[Epoch:    7] cost = 0.307103227\n",
      "[Epoch:    8] cost = 0.305624824\n",
      "[Epoch:    9] cost = 0.305231285\n",
      "[Epoch:   10] cost = 0.30407103\n",
      "[Epoch:   11] cost = 0.304704691\n",
      "[Epoch:   12] cost = 0.302756819\n",
      "[Epoch:   13] cost = 0.302836068\n",
      "[Epoch:   14] cost = 0.302418209\n",
      "[Epoch:   15] cost = 0.302424194\n",
      "Learning Finished!\n",
      "Accuracy: 0.9832\n",
      "Label:  [2]\n",
      "Prediction:  [2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#MNIST and High-level TF API\n",
    "from tensorflow.contrib.layers import fully_connected, batch_norm, dropout\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "keep_prob = 0.7\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "train_mode = tf.placeholder(tf.bool, name='train_mode')\n",
    "\n",
    "hidden_output_size = 512\n",
    "final_output_size = 10\n",
    "\n",
    "xavier_init = tf.contrib.layers.xavier_initializer()\n",
    "bn_params = {\n",
    "    'is_training': train_mode,\n",
    "    'decay': 0.9,\n",
    "    'updates_collections': None\n",
    "}\n",
    "\n",
    "with arg_scope([fully_connected],\n",
    "               activation_fn=tf.nn.relu,\n",
    "               weights_initializer=xavier_init,\n",
    "               biases_initializer=None,\n",
    "               normalizer_fn=batch_norm,\n",
    "               normalizer_params=bn_params\n",
    "               ):\n",
    "    hidden_layer1 = fully_connected(X, hidden_output_size, scope=\"h1\")\n",
    "    h1_drop = dropout(hidden_layer1, keep_prob, is_training=train_mode)\n",
    "    hidden_layer2 = fully_connected(h1_drop, hidden_output_size, scope=\"h2\")\n",
    "    h2_drop = dropout(hidden_layer2, keep_prob, is_training=train_mode)\n",
    "    hidden_layer3 = fully_connected(h2_drop, hidden_output_size, scope=\"h3\")\n",
    "    h3_drop = dropout(hidden_layer3, keep_prob, is_training=train_mode)\n",
    "    hidden_layer4 = fully_connected(h3_drop, hidden_output_size, scope=\"h4\")\n",
    "    h4_drop = dropout(hidden_layer4, keep_prob, is_training=train_mode)\n",
    "    hypothesis = fully_connected(h4_drop, final_output_size, activation_fn=None, scope=\"hypothesis\")\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict_train = {X: batch_xs, Y: batch_ys, train_mode: True}\n",
    "        feed_dict_cost = {X: batch_xs, Y: batch_ys, train_mode: False}\n",
    "        opt = sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "        c = sess.run(cost, feed_dict=feed_dict_cost)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print(\"[Epoch: {:>4}] cost = {:>.9}\".format(epoch + 1, avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, train_mode: False}))\n",
    "\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1], train_mode: False}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "           reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-2-b337aaadad81>:21: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch: 0001 cost = 0.488546528\n",
      "Epoch: 0002 cost = 0.159637394\n",
      "Epoch: 0003 cost = 0.126090051\n",
      "Epoch: 0004 cost = 0.107046438\n",
      "Epoch: 0005 cost = 0.093400184\n",
      "Epoch: 0006 cost = 0.091438809\n",
      "Epoch: 0007 cost = 0.091849969\n",
      "Epoch: 0008 cost = 0.070853417\n",
      "Epoch: 0009 cost = 0.083745525\n",
      "Epoch: 0010 cost = 0.069688527\n",
      "Epoch: 0011 cost = 0.062600825\n",
      "Epoch: 0012 cost = 0.058266515\n",
      "Epoch: 0013 cost = 0.058314489\n",
      "Epoch: 0014 cost = 0.052436945\n",
      "Epoch: 0015 cost = 0.052838520\n",
      "Epoch: 0016 cost = 0.051160841\n",
      "Epoch: 0017 cost = 0.052705045\n",
      "Epoch: 0018 cost = 0.051496073\n",
      "Epoch: 0019 cost = 0.043858985\n",
      "Epoch: 0020 cost = 0.044197814\n",
      "Epoch: 0021 cost = 0.045294741\n",
      "Epoch: 0022 cost = 0.041473348\n",
      "Epoch: 0023 cost = 0.037360876\n",
      "Epoch: 0024 cost = 0.034908144\n",
      "Epoch: 0025 cost = 0.036589198\n",
      "Epoch: 0026 cost = 0.041686447\n",
      "Epoch: 0027 cost = 0.031939938\n",
      "Epoch: 0028 cost = 0.037616072\n",
      "Epoch: 0029 cost = 0.032801353\n",
      "Epoch: 0030 cost = 0.031393159\n",
      "Epoch: 0031 cost = 0.035083494\n",
      "Epoch: 0032 cost = 0.034509113\n",
      "Epoch: 0033 cost = 0.033362468\n",
      "Epoch: 0034 cost = 0.031779661\n",
      "Epoch: 0035 cost = 0.040370651\n",
      "Epoch: 0036 cost = 0.031316615\n",
      "Epoch: 0037 cost = 0.026824735\n",
      "Epoch: 0038 cost = 0.033808214\n",
      "Epoch: 0039 cost = 0.107148720\n",
      "Epoch: 0040 cost = 0.025513316\n",
      "Epoch: 0041 cost = 0.016462884\n",
      "Epoch: 0042 cost = 0.022998282\n",
      "Epoch: 0043 cost = 0.023449947\n",
      "Epoch: 0044 cost = 0.023452592\n",
      "Epoch: 0045 cost = 0.026029535\n",
      "Epoch: 0046 cost = 0.035632428\n",
      "Epoch: 0047 cost = 0.028535970\n",
      "Epoch: 0048 cost = 0.023282180\n",
      "Epoch: 0049 cost = 0.013901218\n",
      "Epoch: 0050 cost = 0.038405670\n",
      "Learning Finished!\n",
      "Accuracy: 0.9778\n",
      "Label:  [6]\n",
      "Prediction:  [6]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MNIST and Dropout\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numbers\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.framework import tensor_util\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import random_ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.layers import utils\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "def selu(x):\n",
    "    with ops.name_scope('elu') as scope:\n",
    "        alpha = 1.6732632423543772848170429916717\n",
    "        scale = 1.0507009873554804934193349852946\n",
    "        return scale*tf.where(x>=0.0, x, alpha*tf.nn.elu(x))\n",
    "\n",
    "\n",
    "def dropout_selu(x, keep_prob, alpha= -1.7580993408473766, fixedPointMean=0.0, fixedPointVar=1.0,\n",
    "                 noise_shape=None, seed=None, name=None, training=False):\n",
    "\n",
    "    def dropout_selu_impl(x, rate, alpha, noise_shape, seed, name):\n",
    "        keep_prob = 1.0 - rate\n",
    "        x = ops.convert_to_tensor(x, name=\"x\")\n",
    "        if isinstance(keep_prob, numbers.Real) and not 0 < keep_prob <= 1:\n",
    "            raise ValueError(\"keep_prob must be a scalar tensor or a float in the \"\n",
    "                                             \"range (0, 1], got %g\" % keep_prob)\n",
    "        keep_prob = ops.convert_to_tensor(keep_prob, dtype=x.dtype, name=\"keep_prob\")\n",
    "        keep_prob.get_shape().assert_is_compatible_with(tensor_shape.scalar())\n",
    "\n",
    "        alpha = ops.convert_to_tensor(alpha, dtype=x.dtype, name=\"alpha\")\n",
    "        keep_prob.get_shape().assert_is_compatible_with(tensor_shape.scalar())\n",
    "\n",
    "        if tensor_util.constant_value(keep_prob) == 1:\n",
    "            return x\n",
    "\n",
    "        noise_shape = noise_shape if noise_shape is not None else array_ops.shape(x)\n",
    "        random_tensor = keep_prob\n",
    "        random_tensor += random_ops.random_uniform(noise_shape, seed=seed, dtype=x.dtype)\n",
    "        binary_tensor = math_ops.floor(random_tensor)\n",
    "        ret = x * binary_tensor + alpha * (1-binary_tensor)\n",
    "\n",
    "        a = tf.sqrt(fixedPointVar / (keep_prob *((1-keep_prob) * tf.pow(alpha-fixedPointMean,2) + fixedPointVar)))\n",
    "\n",
    "        b = fixedPointMean - a * (keep_prob * fixedPointMean + (1 - keep_prob) * alpha)\n",
    "        ret = a * ret + b\n",
    "        ret.set_shape(x.get_shape())\n",
    "        return ret\n",
    "\n",
    "    with ops.name_scope(name, \"dropout\", [x]) as name:\n",
    "        return utils.smart_cond(training,\n",
    "                                lambda: dropout_selu_impl(x, keep_prob, alpha, noise_shape, seed, name),\n",
    "                                lambda: array_ops.identity(x))\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 50\n",
    "batch_size = 100\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([512]))\n",
    "L1 = selu(tf.matmul(X, W1) + b1)\n",
    "L1 = dropout_selu(L1, keep_prob=keep_prob)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([512]))\n",
    "L2 = selu(tf.matmul(L1, W2) + b2)\n",
    "L2 = dropout_selu(L2, keep_prob=keep_prob)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([512]))\n",
    "L3 = selu(tf.matmul(L2, W3) + b3)\n",
    "L3 = dropout_selu(L3, keep_prob=keep_prob)\n",
    "\n",
    "W4 = tf.get_variable(\"W4\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([512]))\n",
    "L4 = selu(tf.matmul(L3, W4) + b4)\n",
    "L4 = dropout_selu(L4, keep_prob=keep_prob)\n",
    "\n",
    "W5 = tf.get_variable(\"W5\", shape=[512, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L4, W5) + b5\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
    "\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-3-625d94db2cd7>:16: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "88.0\n",
      "817.0\n",
      "881.0\n",
      "892.0\n",
      "910.0\n",
      "890.0\n",
      "914.0\n",
      "904.0\n",
      "928.0\n",
      "919.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "w1 = tf.Variable(tf.truncated_normal([784, 30]))\n",
    "b1 = tf.Variable(tf.truncated_normal([1, 30]))\n",
    "w2 = tf.Variable(tf.truncated_normal([30, 10]))\n",
    "b2 = tf.Variable(tf.truncated_normal([1, 10]))\n",
    "\n",
    "\n",
    "def sigma(x):\n",
    "    return tf.div(tf.constant(1.0),\n",
    "                  tf.add(tf.constant(1.0), tf.exp(-x)))\n",
    "\n",
    "\n",
    "def sigma_prime(x):\n",
    "    return sigma(x) * (1 - sigma(x))\n",
    "\n",
    "l1 = tf.add(tf.matmul(X, w1), b1)\n",
    "a1 = sigma(l1)\n",
    "l2 = tf.add(tf.matmul(a1, w2), b2)\n",
    "y_pred = sigma(l2)\n",
    "\n",
    "assert y_pred.shape.as_list() == Y.shape.as_list()\n",
    "diff = (y_pred - Y)\n",
    "\n",
    "d_l2 = diff * sigma_prime(l2)\n",
    "d_b2 = d_l2\n",
    "d_w2 = tf.matmul(tf.transpose(a1), d_l2)\n",
    "\n",
    "d_a1 = tf.matmul(d_l2, tf.transpose(w2))\n",
    "d_l1 = d_a1 * sigma_prime(l1)\n",
    "d_b1 = d_l1\n",
    "d_w1 = tf.matmul(tf.transpose(X), d_l1)\n",
    "\n",
    "learning_rate = 0.5\n",
    "step = [\n",
    "    tf.assign(w1, w1 - learning_rate * d_w1),\n",
    "    tf.assign(b1, b1 - learning_rate *\n",
    "              tf.reduce_mean(d_b1, reduction_indices=[0])),\n",
    "    tf.assign(w2, w2 - learning_rate * d_w2),\n",
    "    tf.assign(b2, b2 - learning_rate *\n",
    "              tf.reduce_mean(d_b2, reduction_indices=[0]))\n",
    "]\n",
    "\n",
    "acct_mat = tf.equal(tf.argmax(y_pred, 1), tf.argmax(Y, 1))\n",
    "acct_res = tf.reduce_sum(tf.cast(acct_mat, tf.float32))\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(10000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(10)\n",
    "    sess.run(step, feed_dict={X: batch_xs,\n",
    "                              Y: batch_ys})\n",
    "    if i % 1000 == 0:\n",
    "        res = sess.run(acct_res, feed_dict={X: mnist.test.images[:1000],\n",
    "                                            Y: mnist.test.labels[:1000]})\n",
    "        print(res)\n",
    "\n",
    "cost = diff * diff\n",
    "step = tf.train.GradientDescentOptimizer(0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
