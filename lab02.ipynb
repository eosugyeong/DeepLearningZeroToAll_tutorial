{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ehrme\\AppData\\Local\\Continuum\\anaconda3\\envs\\sugyeong_2019\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.8532214 [-0.51864403] [0.7317075]\n",
      "20 0.23955713 [0.41284764] [1.0756886]\n",
      "40 0.16330846 [0.5223417] [1.0611632]\n",
      "60 0.14782745 [0.5525884] [1.0147232]\n",
      "80 0.13425477 [0.57435757] [0.96736157]\n",
      "100 0.12193229 [0.59443194] [0.92193025]\n",
      "120 0.1107409 [0.6134988] [0.87860596]\n",
      "140 0.10057668 [0.63166356] [0.83731496]\n",
      "160 0.09134536 [0.64897406] [0.79796433]\n",
      "180 0.08296129 [0.665471] [0.76046294]\n",
      "200 0.07534679 [0.6811927] [0.72472394]\n",
      "220 0.06843112 [0.6961755] [0.69066447]\n",
      "240 0.06215022 [0.7104541] [0.65820587]\n",
      "260 0.056445822 [0.7240618] [0.62727255]\n",
      "280 0.051265027 [0.7370298] [0.5977931]\n",
      "300 0.04655972 [0.74938846] [0.56969905]\n",
      "320 0.042286262 [0.7611663] [0.54292524]\n",
      "340 0.03840511 [0.77239054] [0.5174098]\n",
      "360 0.034880098 [0.78308743] [0.49309325]\n",
      "380 0.031678643 [0.7932815] [0.46991965]\n",
      "400 0.028771052 [0.8029965] [0.44783515]\n",
      "420 0.026130335 [0.8122549] [0.42678857]\n",
      "440 0.023731992 [0.8210783] [0.40673116]\n",
      "460 0.021553775 [0.82948697] [0.38761625]\n",
      "480 0.019575477 [0.8375004] [0.36939973]\n",
      "500 0.017778782 [0.84513724] [0.3520394]\n",
      "520 0.016146956 [0.8524152] [0.33549488]\n",
      "540 0.014664945 [0.85935116] [0.31972784]\n",
      "560 0.013318921 [0.86596113] [0.30470178]\n",
      "580 0.012096476 [0.8722604] [0.29038197]\n",
      "600 0.010986209 [0.8782637] [0.27673513]\n",
      "620 0.0099778585 [0.8839849] [0.26372957]\n",
      "640 0.0090620415 [0.8894372] [0.2513353]\n",
      "660 0.008230305 [0.89463323] [0.23952347]\n",
      "680 0.0074748904 [0.8995851] [0.22826673]\n",
      "700 0.0067888102 [0.9043042] [0.21753903]\n",
      "720 0.006165708 [0.9088016] [0.20731552]\n",
      "740 0.005599793 [0.91308755] [0.19757245]\n",
      "760 0.005085828 [0.9171721] [0.18828732]\n",
      "780 0.004619029 [0.92106473] [0.17943849]\n",
      "800 0.004195081 [0.92477435] [0.17100555]\n",
      "820 0.0038100418 [0.9283096] [0.16296896]\n",
      "840 0.0034603353 [0.9316789] [0.15530999]\n",
      "860 0.0031427376 [0.93488973] [0.14801098]\n",
      "880 0.0028542753 [0.9379497] [0.141055]\n",
      "900 0.0025923022 [0.9408659] [0.13442586]\n",
      "920 0.0023543744 [0.9436449] [0.12810835]\n",
      "940 0.0021382761 [0.9462934] [0.12208772]\n",
      "960 0.0019420204 [0.9488173] [0.11635005]\n",
      "980 0.0017637741 [0.95122284] [0.11088205]\n",
      "1000 0.0016018845 [0.9535151] [0.10567097]\n",
      "1020 0.0014548538 [0.95569974] [0.10070483]\n",
      "1040 0.0013213274 [0.95778173] [0.09597208]\n",
      "1060 0.0012000492 [0.9597658] [0.09146179]\n",
      "1080 0.0010899013 [0.9616567] [0.08716343]\n",
      "1100 0.0009898668 [0.96345866] [0.08306704]\n",
      "1120 0.0008990162 [0.965176] [0.07916319]\n",
      "1140 0.0008164973 [0.9668126] [0.07544279]\n",
      "1160 0.00074155815 [0.9683723] [0.07189727]\n",
      "1180 0.00067349407 [0.96985865] [0.06851842]\n",
      "1200 0.00061168004 [0.9712752] [0.06529827]\n",
      "1220 0.0005555386 [0.97262514] [0.06222947]\n",
      "1240 0.00050454825 [0.97391164] [0.05930493]\n",
      "1260 0.00045823737 [0.9751377] [0.05651781]\n",
      "1280 0.000416177 [0.9763062] [0.05386166]\n",
      "1300 0.00037797994 [0.9774197] [0.05133034]\n",
      "1320 0.00034328547 [0.9784809] [0.04891801]\n",
      "1340 0.00031177886 [0.979492] [0.0466191]\n",
      "1360 0.00028316295 [0.980456] [0.04442823]\n",
      "1380 0.00025717358 [0.9813745] [0.04234024]\n",
      "1400 0.00023356748 [0.9822498] [0.04035038]\n",
      "1420 0.00021213142 [0.983084] [0.03845407]\n",
      "1440 0.00019266146 [0.98387897] [0.03664686]\n",
      "1460 0.00017497898 [0.98463666] [0.03492458]\n",
      "1480 0.00015891637 [0.98535866] [0.03328322]\n",
      "1500 0.00014433025 [0.9860468] [0.03171902]\n",
      "1520 0.0001310828 [0.98670256] [0.03022833]\n",
      "1540 0.00011905224 [0.98732746] [0.02880769]\n",
      "1560 0.00010812469 [0.987923] [0.02745382]\n",
      "1580 9.820054e-05 [0.9884906] [0.02616359]\n",
      "1600 8.91872e-05 [0.9890315] [0.02493402]\n",
      "1620 8.100026e-05 [0.9895471] [0.02376222]\n",
      "1640 7.356614e-05 [0.99003834] [0.02264544]\n",
      "1660 6.68132e-05 [0.9905065] [0.02158113]\n",
      "1680 6.068123e-05 [0.9909526] [0.02056688]\n",
      "1700 5.5111315e-05 [0.99137783] [0.0196003]\n",
      "1720 5.005382e-05 [0.991783] [0.01867913]\n",
      "1740 4.5458408e-05 [0.9921692] [0.01780128]\n",
      "1760 4.1287498e-05 [0.9925372] [0.01696468]\n",
      "1780 3.749722e-05 [0.992888] [0.01616741]\n",
      "1800 3.40562e-05 [0.9932222] [0.01540759]\n",
      "1820 3.0930503e-05 [0.9935407] [0.0146835]\n",
      "1840 2.8090648e-05 [0.9938443] [0.01399342]\n",
      "1860 2.5512754e-05 [0.99413353] [0.01333577]\n",
      "1880 2.3171082e-05 [0.99440926] [0.01270906]\n",
      "1900 2.1044476e-05 [0.994672] [0.0121118]\n",
      "1920 1.9113364e-05 [0.99492234] [0.01154261]\n",
      "1940 1.7358647e-05 [0.99516106] [0.01100018]\n",
      "1960 1.576548e-05 [0.9953884] [0.0104832]\n",
      "1980 1.43187035e-05 [0.9956052] [0.00999053]\n",
      "2000 1.3004239e-05 [0.9958117] [0.009521]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3] #x가1일때y가1 이런식임\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\") #w와 b를 variable로 지정\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "#tensorflow가 실행하는 variable이다라고 볼 수 있음.\n",
    "#w와b의 값을 모르니 처음에는 랜덤한 값을 준다(tf.random_normal)\n",
    "\n",
    "hypothesis = x_train * W + b #hypothesis node\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
    "#기본적으로 cost 함수를 그대로 컴퓨터에 넣어줌\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "#cost를 minimize해야 함, train: 노드 이름\n",
    "\n",
    "sess =  tf.Session()#session을 만듦\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001): #step: 2000번\n",
    "    sess.run(train)\n",
    "\n",
    "    if step % 20 == 0: #20번에 한 번씩 출력해라a\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13.458786 [0.07122885] [1.4086803]\n",
      "20 0.04448648 [0.86041147] [1.5902077]\n",
      "40 0.038611513 [0.872843] [1.5590148]\n",
      "60 0.03371972 [0.88118553] [1.5289576]\n",
      "80 0.02944763 [0.88896686] [1.5008647]\n",
      "100 0.02571688 [0.89623845] [1.474612]\n",
      "120 0.022458721 [0.9030339] [1.4500782]\n",
      "140 0.019613404 [0.90938425] [1.4271514]\n",
      "160 0.017128494 [0.91531885] [1.4057258]\n",
      "180 0.014958441 [0.92086464] [1.3857037]\n",
      "200 0.013063301 [0.92604727] [1.3669926]\n",
      "220 0.011408299 [0.93089044] [1.3495072]\n",
      "240 0.009962946 [0.9354165] [1.3331667]\n",
      "260 0.008700711 [0.9396462] [1.3178965]\n",
      "280 0.007598409 [0.94359875] [1.3036262]\n",
      "300 0.006635734 [0.94729257] [1.2902905]\n",
      "320 0.005795022 [0.9507444] [1.2778281]\n",
      "340 0.0050608525 [0.95397025] [1.2661821]\n",
      "360 0.004419682 [0.9569847] [1.2552989]\n",
      "380 0.0038597349 [0.95980185] [1.2451282]\n",
      "400 0.0033707432 [0.9624344] [1.2356236]\n",
      "420 0.0029436946 [0.96489465] [1.2267414]\n",
      "440 0.0025707572 [0.96719366] [1.2184411]\n",
      "460 0.0022450567 [0.96934223] [1.2106843]\n",
      "480 0.0019606147 [0.97135] [1.2034353]\n",
      "500 0.0017122254 [0.97322637] [1.1966612]\n",
      "520 0.0014952985 [0.97497976] [1.190331]\n",
      "540 0.0013058617 [0.97661835] [1.1844152]\n",
      "560 0.0011404216 [0.9781496] [1.1788868]\n",
      "580 0.0009959412 [0.9795805] [1.1737205]\n",
      "600 0.00086975266 [0.98091793] [1.1688921]\n",
      "620 0.0007595619 [0.98216766] [1.1643803]\n",
      "640 0.000663328 [0.9833355] [1.1601641]\n",
      "660 0.00057929836 [0.98442686] [1.156224]\n",
      "680 0.0005059034 [0.98544675] [1.1525419]\n",
      "700 0.00044181236 [0.9863998] [1.149101]\n",
      "720 0.0003858334 [0.9872905] [1.1458851]\n",
      "740 0.00033694718 [0.98812294] [1.14288]\n",
      "760 0.00029425634 [0.98890084] [1.1400714]\n",
      "780 0.0002569772 [0.9896277] [1.137447]\n",
      "800 0.00022441943 [0.99030703] [1.1349946]\n",
      "820 0.00019598706 [0.9909418] [1.1327027]\n",
      "840 0.0001711493 [0.9915352] [1.1305605]\n",
      "860 0.00014946984 [0.9920895] [1.1285591]\n",
      "880 0.00013053168 [0.9926076] [1.1266888]\n",
      "900 0.00011399478 [0.99309176] [1.124941]\n",
      "920 9.955284e-05 [0.99354416] [1.1233076]\n",
      "940 8.694115e-05 [0.993967] [1.1217811]\n",
      "960 7.592801e-05 [0.994362] [1.120355]\n",
      "980 6.630849e-05 [0.9947312] [1.119022]\n",
      "1000 5.790607e-05 [0.99507624] [1.1177762]\n",
      "1020 5.057129e-05 [0.99539876] [1.1166121]\n",
      "1040 4.4165146e-05 [0.99570006] [1.1155242]\n",
      "1060 3.8569906e-05 [0.99598163] [1.1145076]\n",
      "1080 3.368417e-05 [0.9962448] [1.1135576]\n",
      "1100 2.9416933e-05 [0.99649066] [1.1126696]\n",
      "1120 2.5688929e-05 [0.9967205] [1.1118399]\n",
      "1140 2.243444e-05 [0.9969353] [1.1110644]\n",
      "1160 1.9593772e-05 [0.997136] [1.1103401]\n",
      "1180 1.711095e-05 [0.9973234] [1.109663]\n",
      "1200 1.4943946e-05 [0.99749875] [1.1090302]\n",
      "1220 1.3050265e-05 [0.99766254] [1.1084388]\n",
      "1240 1.1397273e-05 [0.99781567] [1.1078862]\n",
      "1260 9.95416e-06 [0.99795866] [1.1073698]\n",
      "1280 8.692916e-06 [0.9980923] [1.1068872]\n",
      "1300 7.5917183e-06 [0.9982172] [1.1064363]\n",
      "1320 6.6297057e-06 [0.998334] [1.1060147]\n",
      "1340 5.7896427e-06 [0.9984431] [1.1056207]\n",
      "1360 5.0561844e-06 [0.99854505] [1.1052527]\n",
      "1380 4.415405e-06 [0.99864036] [1.1049086]\n",
      "1400 3.855993e-06 [0.9987294] [1.1045871]\n",
      "1420 3.3675915e-06 [0.9988126] [1.1042868]\n",
      "1440 2.9410953e-06 [0.99889034] [1.1040059]\n",
      "1460 2.5683335e-06 [0.998963] [1.1037437]\n",
      "1480 2.2433865e-06 [0.99903095] [1.1034985]\n",
      "1500 1.958969e-06 [0.9990945] [1.1032692]\n",
      "1520 1.7104779e-06 [0.9991537] [1.1030551]\n",
      "1540 1.4940327e-06 [0.99920917] [1.1028551]\n",
      "1560 1.3045479e-06 [0.9992609] [1.1026682]\n",
      "1580 1.1395923e-06 [0.9993093] [1.1024935]\n",
      "1600 9.948892e-07 [0.99935454] [1.1023302]\n",
      "1620 8.689187e-07 [0.9993968] [1.1021776]\n",
      "1640 7.589796e-07 [0.9994363] [1.1020349]\n",
      "1660 6.627997e-07 [0.9994733] [1.1019017]\n",
      "1680 5.787661e-07 [0.9995077] [1.1017771]\n",
      "1700 5.055265e-07 [0.99954] [1.1016607]\n",
      "1720 4.4147728e-07 [0.9995701] [1.1015521]\n",
      "1740 3.8568496e-07 [0.9995982] [1.1014504]\n",
      "1760 3.3682585e-07 [0.99962455] [1.1013554]\n",
      "1780 2.940019e-07 [0.99964905] [1.1012667]\n",
      "1800 2.5680515e-07 [0.9996721] [1.1011838]\n",
      "1820 2.241995e-07 [0.9996935] [1.1011063]\n",
      "1840 1.9587864e-07 [0.9997136] [1.1010339]\n",
      "1860 1.7110719e-07 [0.9997323] [1.1009662]\n",
      "1880 1.4947646e-07 [0.99974984] [1.1009029]\n",
      "1900 1.3047944e-07 [0.99976623] [1.1008438]\n",
      "1920 1.1392159e-07 [0.9997816] [1.1007885]\n",
      "1940 9.957004e-08 [0.99979585] [1.1007371]\n",
      "1960 8.6982936e-08 [0.99980915] [1.1006887]\n",
      "1980 7.597784e-08 [0.9998216] [1.1006439]\n",
      "2000 6.641331e-08 [0.9998333] [1.1006018]\n",
      "[6.099768]\n",
      "[3.600185]\n",
      "[2.6003518 4.6000185]\n",
      "0 6.59241e-08 [0.9998338] [1.1005998]\n",
      "20 5.7595116e-08 [0.99984473] [1.1005605]\n",
      "40 5.0341804e-08 [0.99985486] [1.1005238]\n",
      "60 4.3980084e-08 [0.99986434] [1.1004897]\n",
      "80 3.8427892e-08 [0.9998732] [1.1004577]\n",
      "100 3.3526156e-08 [0.9998815] [1.1004279]\n",
      "120 2.9329716e-08 [0.99988925] [1.1003999]\n",
      "140 2.5591612e-08 [0.9998964] [1.1003736]\n",
      "160 2.2399172e-08 [0.99990314] [1.1003495]\n",
      "180 1.9559058e-08 [0.9999095] [1.1003265]\n",
      "200 1.7075468e-08 [0.9999155] [1.1003051]\n",
      "220 1.4943192e-08 [0.9999209] [1.1002854]\n",
      "240 1.301355e-08 [0.99992615] [1.1002663]\n",
      "260 1.1425584e-08 [0.9999309] [1.1002495]\n",
      "280 9.961252e-09 [0.9999355] [1.1002328]\n",
      "300 8.7179615e-09 [0.9999396] [1.1002179]\n",
      "320 7.60333e-09 [0.9999435] [1.1002036]\n",
      "340 6.627181e-09 [0.9999473] [1.1001903]\n",
      "360 5.824461e-09 [0.9999506] [1.1001784]\n",
      "380 5.085417e-09 [0.9999539] [1.1001664]\n",
      "400 4.4059107e-09 [0.99995697] [1.1001552]\n",
      "420 3.900368e-09 [0.9999596] [1.1001457]\n",
      "440 3.3994296e-09 [0.99996215] [1.1001362]\n",
      "460 2.9391345e-09 [0.9999648] [1.1001266]\n",
      "480 2.5937084e-09 [0.9999671] [1.100119]\n",
      "500 2.2931772e-09 [0.99996907] [1.1001118]\n",
      "520 2.0129618e-09 [0.99997103] [1.1001047]\n",
      "540 1.7492425e-09 [0.99997294] [1.1000975]\n",
      "560 1.506487e-09 [0.9999749] [1.1000904]\n",
      "580 1.3216322e-09 [0.99997646] [1.1000849]\n",
      "600 1.1777501e-09 [0.99997777] [1.1000801]\n",
      "620 1.0461463e-09 [0.9999791] [1.1000754]\n",
      "640 9.11416e-10 [0.9999804] [1.1000706]\n",
      "660 7.9504614e-10 [0.99998164] [1.1000658]\n",
      "680 6.850314e-10 [0.99998295] [1.100061]\n",
      "700 5.8355454e-10 [0.99998426] [1.1000563]\n",
      "720 5.0727067e-10 [0.99998546] [1.1000525]\n",
      "740 4.5251908e-10 [0.99998623] [1.1000497]\n",
      "760 4.126491e-10 [0.99998695] [1.1000473]\n",
      "780 3.7064182e-10 [0.9999876] [1.100045]\n",
      "800 3.327841e-10 [0.9999882] [1.1000426]\n",
      "820 2.9814373e-10 [0.99998885] [1.1000402]\n",
      "840 2.6466296e-10 [0.9999895] [1.1000378]\n",
      "860 2.2988615e-10 [0.99999017] [1.1000354]\n",
      "880 2.02283e-10 [0.9999908] [1.100033]\n",
      "900 1.7485036e-10 [0.9999914] [1.1000307]\n",
      "920 1.4684928e-10 [0.99999213] [1.1000283]\n",
      "940 1.225203e-10 [0.9999927] [1.1000259]\n",
      "960 1.01908884e-10 [0.9999934] [1.1000235]\n",
      "980 8.126335e-11 [0.99999404] [1.1000211]\n",
      "1000 6.5278984e-11 [0.99999475] [1.1000189]\n",
      "1020 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1040 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1060 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1080 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1100 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1120 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1140 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1160 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1180 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1200 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1220 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1240 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1260 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1280 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1300 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1320 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1340 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1360 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1380 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1400 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1420 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1440 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1460 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1480 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1500 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1520 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1540 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1560 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1580 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1600 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1620 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1640 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1660 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1680 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1700 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1720 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1740 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1760 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1780 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1800 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1820 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1840 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1860 6.180016e-11 [0.9999948] [1.1000184]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1880 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1900 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1920 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1940 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1960 6.180016e-11 [0.9999948] [1.1000184]\n",
      "1980 6.180016e-11 [0.9999948] [1.1000184]\n",
      "2000 6.180016e-11 [0.9999948] [1.1000184]\n",
      "[6.0999928]\n",
      "[3.6000056]\n",
      "[2.6000106 4.6000004]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "X = tf.placeholder(tf.float32, shape=[None]) #placeholder로 선언\n",
    "Y = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "hypothesis = X * W + b\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(2001):\n",
    "        _, cost_val, W_val, b_val = sess.run(\n",
    "            [train, cost, W, b], feed_dict={X: [1, 2, 3, 4, 5], Y: [2.1, 3.1, 4.1, 5.1, 6.1]}\n",
    "        ) #좀더 복잡하게\n",
    "        if step % 20 == 0:\n",
    "            print(step, cost_val, W_val, b_val)\n",
    "\n",
    "    print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
    "    print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "    print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))\n",
    "\n",
    "    for step in range(2001): #2000번 실행\n",
    "        _, cost_val, W_val, b_val = sess.run(\n",
    "            [train, cost, W, b],\n",
    "            feed_dict={X: [1, 2, 3, 4, 5], Y: [2.1, 3.1, 4.1, 5.1, 6.1]},\n",
    "        )\n",
    "        if step % 20 == 0: #20번에 한 번 출력\n",
    "            print(step, , W_val, b_val)\n",
    "\n",
    "    print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
    "    print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "    print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
