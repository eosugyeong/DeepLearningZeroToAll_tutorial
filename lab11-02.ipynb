{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_DATA/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_DATA/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_DATA/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_DATA/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_DATA/', one_hot = True)\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Convolution Layer1>\n",
      "\n",
      "convolution:  Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "relu함수 적용:  Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "pooling 적용:  Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
      "\n",
      "<Convolution Layer2>\n",
      "\n",
      "convolution:  Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "relu 통과:  Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "pooling:  Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "reshape:  Tensor(\"Reshape_1:0\", shape=(?, 3136), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#conv layer 1(첫 번째 레이어고고)\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "#None: n개의 이미지, 784개의 값\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "#28X28, 1:색깔, -1:N개 (알아서 해라)\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev = 0.01))\n",
    "#3X3 filter, num_of_color = 1, num_of_lifters = 32\n",
    "#32개의 convolution값들이 생겨난다.\n",
    "\n",
    "print('<Convolution Layer1>\\n')\n",
    "\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides = [1,1,1,1], padding = 'SAME')\n",
    "print('convolution: ',L1)\n",
    "'''padding = \"SAME\": 스트라이드가 1X1이 기준일 때 WEIGHT에 상관없이\n",
    "L1의 출력값은 입력의 이미지 사이즈와 같다\n",
    "CONVOLUTION을 통과해서 나오면 28X28 사이즈,\n",
    "대신 필터를 32개를 사용했기 때문에 32개의 convolution값들이 생김.'''\n",
    "L1 = tf.nn.relu(L1)\n",
    "print('relu함수 적용: ',L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "print('pooling 적용: ',L1)\n",
    "#padding = 2x2, stride가 1이면 28x28이지만, 2이기때문에 14x14가 나옴, 채널의 개수는 32개\n",
    "\n",
    "#conv layer2(두번째 레이어 고고)\n",
    "W2 = tf.Variable(tf.random_normal([3,3,32,64], stddev = 0.01))\n",
    "#pooling 적용:  Tensor(\"MaxPool_2:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "#3x3 filter, 앞에서 32는 똑같이, 이번엔 64개의 필터로 설정하겠다.\n",
    "#conv => (?, 14, 14, 64) 필터를 64개 사용했기 때문\n",
    "#pool => (?, 7, 7, 64) 스트라이드를 2x2로 했기 때문에 7x7\n",
    "print('\\n<Convolution Layer2>\\n')\n",
    "L2 = tf.nn.conv2d(L1, W2, strides = [1,1,1,1], padding = 'SAME')\n",
    "print('convolution: ', L2)\n",
    "L2 = tf.nn.relu(L2)\n",
    "print('relu 통과: ', L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "print('pooling: ', L2)\n",
    "L2 = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
    "print('reshape: ', L2)\n",
    "#입체인 l2를 reshape로 펼친다. 7*7*64로 reshape, 이게 n개만큼 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch:  0001 cost =  0.401931533\n",
      "Epoch:  0002 cost =  0.106304011\n",
      "Epoch:  0003 cost =  0.078407679\n",
      "Epoch:  0004 cost =  0.064410166\n",
      "Epoch:  0005 cost =  0.055115400\n",
      "Epoch:  0006 cost =  0.047130910\n",
      "Epoch:  0007 cost =  0.041969337\n",
      "Epoch:  0008 cost =  0.036958858\n",
      "Epoch:  0009 cost =  0.033934926\n",
      "Epoch:  0010 cost =  0.029994835\n",
      "Epoch:  0011 cost =  0.025108832\n",
      "Epoch:  0012 cost =  0.024082376\n",
      "Epoch:  0013 cost =  0.020188777\n",
      "Epoch:  0014 cost =  0.019653976\n",
      "Epoch:  0015 cost =  0.016476957\n",
      "Learning Finished!\n",
      "Accuracy:  0.9877\n"
     ]
    }
   ],
   "source": [
    "W3 = tf.get_variable(\"W3\", shape = [7 * 7 * 64, 10], \n",
    "                     initializer = tf.contrib.layers.xavier_initializer())\n",
    "#output:10개(0-9까지)\n",
    "\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L2, W3) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = hypothesis, labels = Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict = {X: batch_xs, Y: batch_ys})\n",
    "        avg_cost += c / total_batch\n",
    "    print('Epoch: ', '%04d' % (epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))\n",
    "    \n",
    "print('Learning Finished!')\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy: ', sess.run(accuracy, feed_dict = {X: mnist.test.images, Y: mnist.test.labels}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_DATA/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_DATA/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_DATA/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_DATA/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_DATA/', one_hot = True)\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes some time.\n",
      "Epoch:  0001 cost =  0.374056701\n",
      "Epoch:  0002 cost =  0.096251808\n",
      "Epoch:  0003 cost =  0.071885036\n",
      "Epoch:  0004 cost =  0.058476976\n",
      "Epoch:  0005 cost =  0.050731856\n",
      "Epoch:  0006 cost =  0.046820657\n",
      "Epoch:  0007 cost =  0.041802602\n",
      "Epoch:  0008 cost =  0.039408791\n",
      "Epoch:  0009 cost =  0.036448343\n",
      "Epoch:  0010 cost =  0.033645915\n",
      "Epoch:  0011 cost =  0.031104443\n",
      "Epoch:  0012 cost =  0.031094212\n",
      "Epoch:  0013 cost =  0.028411251\n",
      "Epoch:  0014 cost =  0.028107258\n",
      "Epoch:  0015 cost =  0.025813088\n",
      "Learning Finished!\n",
      "Accuracy:  0.993\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev = 0.01))\n",
    "#    Conv     -> (?, 28, 28, 32)\n",
    "#    Pool     -> (?, 14, 14, 32)\n",
    "\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides = [1,1,1,1], padding = 'SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "L1 = tf.nn.dropout(L1, keep_prob = keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev = 0.01))\n",
    "#    Conv      ->(?, 14, 14, 64)\n",
    "#    Pool      ->(?, 7, 7, 64)\n",
    "\n",
    "L2 = tf.nn.conv2d(L1, W2, strides = [1,1,1,1], padding = 'SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "L2 = tf.nn.dropout(L2, keep_prob = keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev = 0.01))\n",
    "#    Conv      ->(?, 7, 7, 128)\n",
    "#    Pool      ->(?, 4, 4, 128)\n",
    "#    Reshape   ->(?, 4 * 4 * 128) # Flatten them for FC\n",
    "\n",
    "L3 = tf.nn.conv2d(L2, W3, strides = [1,1,1,1], padding = 'SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "L3 = tf.nn.dropout(L3, keep_prob = keep_prob)\n",
    "\n",
    "L3 = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "\n",
    "W4 = tf.get_variable('W4', shape = [128 * 4 * 4, 625],\n",
    "                    initializer = tf.contrib.layers.xavier_initializer())\n",
    "#625개 출력하겠습니다.\n",
    "\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob = keep_prob)\n",
    "\n",
    "W5 = tf.get_variable('W5', shape = [625, 10],\n",
    "                    initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L4, W5) + b5\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits = hypothesis, labels = Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate  = learning_rate).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    print('Learning started. It takes some time.')\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict = {X: batch_xs, Y: batch_ys, keep_prob : 0.7})\n",
    "            avg_cost += c / total_batch\n",
    "        \n",
    "        print('Epoch: ', '%04d' % (epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))\n",
    "        \n",
    "    print('Learning Finished!')\n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print('Accuracy: ', sess.run(accuracy, feed_dict= {\n",
    "        X: mnist.test.images, Y: mnist.test.labels, keep_prob : 1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
